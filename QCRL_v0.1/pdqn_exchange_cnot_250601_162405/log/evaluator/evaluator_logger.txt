[2025-06-01 16:24:12][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 0 finish episode, final reward: -0.5000, current episode: 1
[2025-06-01 16:24:12][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 1 finish episode, final reward: -0.5000, current episode: 2
[2025-06-01 16:24:12][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 2 finish episode, final reward: -0.5000, current episode: 3
[2025-06-01 16:24:12][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 0 finish episode, final reward: -0.5000, current episode: 4
[2025-06-01 16:24:12][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 1 finish episode, final reward: -0.5000, current episode: 4
[2025-06-01 16:24:12][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 2 finish episode, final reward: -0.5000, current episode: 4
[2025-06-01 16:24:12][interaction_serial_evaluator.py:287][INFO] 
+-------+------------+---------------------+---------------+---------------+
| Name  | train_iter | ckpt_name           | episode_count | envstep_count |
+-------+------------+---------------------+---------------+---------------+
| Value | 0.000000   | iteration_0.pth.tar | 4.000000      | 12.000000     |
+-------+------------+---------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 3.000000                | 1.663741      | 7.212659            | 2.404220             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -0.500000   | 0.000000   | -0.500000  | -0.500000  |
+-------+-------------+------------+------------+------------+
+-------+--------------------------+--------------------------+
| Name  | eval_episode_return      | eval_episode_return_mean |
+-------+--------------------------+--------------------------+
| Value | [-0.5, -0.5, -0.5, -0.5] | -0.500000                |
+-------+--------------------------+--------------------------+

[2025-06-01 16:26:07][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 0 finish episode, final reward: -0.5000, current episode: 1
[2025-06-01 16:26:07][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 1 finish episode, final reward: -0.5000, current episode: 2
[2025-06-01 16:26:07][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 2 finish episode, final reward: -0.5000, current episode: 3
[2025-06-01 16:26:07][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 0 finish episode, final reward: -0.5000, current episode: 4
[2025-06-01 16:26:07][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 1 finish episode, final reward: -0.5000, current episode: 4
[2025-06-01 16:26:07][interaction_serial_evaluator.py:261][INFO] [EVALUATOR]env 2 finish episode, final reward: -0.5000, current episode: 4
[2025-06-01 16:26:07][interaction_serial_evaluator.py:287][INFO] 
+-------+------------+---------------------+---------------+---------------+
| Name  | train_iter | ckpt_name           | episode_count | envstep_count |
+-------+------------+---------------------+---------------+---------------+
| Value | 0.000000   | iteration_0.pth.tar | 4.000000      | 12.000000     |
+-------+------------+---------------------+---------------+---------------+
+-------+-------------------------+---------------+---------------------+----------------------+
| Name  | avg_envstep_per_episode | evaluate_time | avg_envstep_per_sec | avg_time_per_episode |
+-------+-------------------------+---------------+---------------------+----------------------+
| Value | 3.000000                | 0.468416      | 25.618250           | 8.539417             |
+-------+-------------------------+---------------+---------------------+----------------------+
+-------+-------------+------------+------------+------------+
| Name  | reward_mean | reward_std | reward_max | reward_min |
+-------+-------------+------------+------------+------------+
| Value | -0.500000   | 0.000000   | -0.500000  | -0.500000  |
+-------+-------------+------------+------------+------------+
+-------+--------------------------+--------------------------+
| Name  | eval_episode_return      | eval_episode_return_mean |
+-------+--------------------------+--------------------------+
| Value | [-0.5, -0.5, -0.5, -0.5] | -0.500000                |
+-------+--------------------------+--------------------------+

