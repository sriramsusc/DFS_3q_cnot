{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde1b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BEST-PATH SEQUENCE  (iteration_174.pth.tar) ===\n",
      "\n",
      "Step  1: pair = 2,  p = +0.9791\n",
      "Step  2: pair = 2,  p = +0.9542\n",
      "Step  3: pair = 2,  p = +0.9816\n",
      "Step  4: pair = 2,  p = +0.9590\n",
      "Step  5: pair = 2,  p = +0.9684\n",
      "Step  6: pair = 2,  p = +0.9791\n",
      "Step  7: pair = 2,  p = +0.9843\n",
      "Step  8: pair = 2,  p = +0.9920\n",
      "Step  9: pair = 2,  p = +0.9974\n",
      "Step 10: pair = 2,  p = +0.9967\n",
      "Step 11: pair = 2,  p = +0.9988\n",
      "Step 12: pair = 2,  p = +0.9982\n",
      "Step 13: pair = 2,  p = +0.9981\n",
      "Step 14: pair = 2,  p = +0.9990\n",
      "Step 15: pair = 2,  p = +0.9991\n",
      "Step 16: pair = 2,  p = +0.9996\n",
      "Step 17: pair = 2,  p = +0.9999\n",
      "Step 18: pair = 2,  p = +0.9999\n",
      "\n",
      "Final metrics:\n",
      " 64×64 fidelity    : 0.071728\n",
      "  9×9 block fidelity: 0.157529\n",
      " Total return       : 61.971058\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────── manual_inference.py ─────────────────────\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "# 1)  Your DI-engine policy\n",
    "from ding.policy.pdqn import PDQNPolicy          # or pdqn_command if that’s your install\n",
    "# 2)  Your custom environment\n",
    "from exch_gym_env import ExchangeCNOTEnvDI\n",
    "\n",
    "# ─── configuration ---------------------------------------------------\n",
    "CKPT = \"pdqn_exchange_cnot_250601_023553/ckpt/iteration_174.pth.tar\"   # adjust path if needed\n",
    "if not os.path.isfile(CKPT):\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {CKPT}\")\n",
    "\n",
    "cfg = edict(\n",
    "    type=\"pdqn\",\n",
    "    cuda=torch.cuda.is_available(),\n",
    "    on_policy=False,\n",
    "\n",
    "    model=dict(\n",
    "        obs_shape=163,\n",
    "        action_shape=edict(\n",
    "            action_type_shape=5,\n",
    "            action_args_shape=1,\n",
    "            encoder_hidden_size_list=[256, 256, 256],\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    collect=dict(n_sample=0),                     # no data collection\n",
    "    other=dict(replay_buffer=dict(replay_buffer_size=1)),  # dummy stub\n",
    "    model_load_mode=\"ckpt\",\n",
    "    load_path=CKPT,\n",
    ")\n",
    "\n",
    "# ─── build policy and load weights -----------------------------------\n",
    "policy = PDQNPolicy(cfg, enable_field=[\"eval\"])\n",
    "ckpt   = torch.load(CKPT, map_location=\"cpu\")\n",
    "\n",
    "# main network\n",
    "policy._model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "# target network (if the algorithm created one)\n",
    "if hasattr(policy, \"_target_model\"):\n",
    "    policy._target_model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "\n",
    "# evaluation proxy (always inference, no ε-greedy, no noise)\n",
    "eval_pol = policy.eval_mode        # ←  IMPORTANT: no parentheses\n",
    "\n",
    "# ─── evaluation run --------------------------------------------------\n",
    "env     = ExchangeCNOTEnvDI(use_act_scale=True)     # same flag as training\n",
    "obs     = env.reset()                               # numpy-array shape (163,)\n",
    "seq     = []                                        # list of (pair_idx, p) tuples\n",
    "total   = 0.0\n",
    "done    = False\n",
    "device  = next(policy._model.parameters()).device   # cpu or cuda\n",
    "\n",
    "while not done and len(seq) < env.max_depth:\n",
    "    obs_t = torch.as_tensor(obs, dtype=torch.float32, device=device)\n",
    "    # PDQN expects a dict mapping env-id → obs tensor\n",
    "    act_dict = eval_pol.forward({0: obs_t})\n",
    "    act      = act_dict[0][\"action\"]\n",
    "    pair_idx = int(act[\"action_type\"])\n",
    "    p_value  = float(act[\"action_args\"])\n",
    "\n",
    "    seq.append((pair_idx, p_value))\n",
    "    obs, reward, done, info = env.step((pair_idx, p_value))\n",
    "    total += reward\n",
    "\n",
    "# ─── print results ----------------------------------------------------\n",
    "print(\"\\n=== BEST-PATH SEQUENCE  (\" + os.path.basename(CKPT) + \") ===\\n\")\n",
    "for t, (idx, p) in enumerate(seq, 1):\n",
    "    print(f\"Step {t:2d}: pair = {idx},  p = {p:+.4f}\")\n",
    "\n",
    "print(\"\\nFinal metrics:\")\n",
    "print(f\" 64×64 fidelity    : {info.get('fid64', np.nan):.6f}\")\n",
    "print(f\"  9×9 block fidelity: {info.get('fid9',  np.nan):.6f}\")\n",
    "print(f\" Total return       : {total:.6f}\")\n",
    "# ────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16778bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"pdqn_exchange_cnot_250601_023553/result.pkl\"          # adjust path if it sits elsewhere\n",
    "\n",
    "with open(file_path, \"rb\") as f:\n",
    "    obj = pickle.load(f)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0de2a6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "stop: <class 'numpy.bool_'>  →  sample: False …\n",
      "env_step: <class 'int'>  →  sample: 25056 …\n",
      "train_iter: <class 'int'>  →  sample: 174 …\n",
      "eval_value: <class 'numpy.float64'>  →  sample: -6.028942584991455 …\n",
      "eval_value_raw: <class 'list'>  →  sample: [-6.028942584991455, -6.028942584991455, -6.028942584991455, -6.028942584991455] …\n",
      "finish_time: <class 'str'>  →  sample: Sun Jun  1 02:56:14 2025 …\n"
     ]
    }
   ],
   "source": [
    "print(type(obj))\n",
    "for k, v in obj.items():\n",
    "    print(f\"{k}: {type(v)}  →  sample: {str(v)[:800]} …\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5efbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pandas as pd\n",
    "\n",
    "# dict → JSON\n",
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(obj, f, indent=2, default=str)   # default=str handles non-JSON types\n",
    "\n",
    "# DataFrame → CSV\n",
    "if isinstance(obj, pd.DataFrame):\n",
    "    obj.to_csv(\"results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
