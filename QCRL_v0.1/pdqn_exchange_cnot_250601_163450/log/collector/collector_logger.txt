[2025-06-01 16:46:04][sample_serial_collector.py:416][INFO] collect end:
episode_count: 840
envstep_count: 15104
train_sample_count: 15104
avg_envstep_per_episode: 17.98095238095238
avg_sample_per_episode: 17.98095238095238
avg_envstep_per_sec: 22.884246346271997
avg_train_sample_per_sec: 22.884246346271997
avg_episode_per_sec: 1.2726937851475422
reward_mean: 10.402639687426227
reward_std: 23.241219930584304
reward_max: 102.0
reward_min: -42.02894238684382
total_envstep_count: 15120
total_train_sample_count: 15104
total_episode_count: 840
