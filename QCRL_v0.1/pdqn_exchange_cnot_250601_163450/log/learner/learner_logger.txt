[2025-06-01 16:34:52][base_learner.py:360][INFO] [RANK0]: DI-engine DRL Policy
PDQN(
  (dis_encoder): FCEncoder(
    (act): ReLU()
    (init): Linear(in_features=163, out_features=128, bias=True)
    (main): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=64, bias=True)
      (3): ReLU()
    )
  )
  (cont_encoder): FCEncoder(
    (act): ReLU()
    (init): Linear(in_features=163, out_features=128, bias=True)
    (main): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=64, bias=True)
      (3): ReLU()
    )
  )
  (cont_head): RegressionHead(
    (main): Sequential(
      (0): Linear(in_features=64, out_features=64, bias=True)
      (1): ReLU()
    )
    (last): Linear(in_features=64, out_features=1, bias=True)
    (tanh): Tanh()
  )
  (dis_head): DuelingHead(
    (A): Sequential(
      (0): Sequential(
        (0): Linear(in_features=65, out_features=65, bias=True)
        (1): ReLU()
      )
      (1): Sequential(
        (0): Linear(in_features=65, out_features=5, bias=True)
      )
    )
    (V): Sequential(
      (0): Sequential(
        (0): Linear(in_features=65, out_features=65, bias=True)
        (1): ReLU()
      )
      (1): Sequential(
        (0): Linear(in_features=65, out_features=1, bias=True)
      )
    )
  )
  (actor_head): ModuleList(
    (0): DuelingHead(
      (A): Sequential(
        (0): Sequential(
          (0): Linear(in_features=65, out_features=65, bias=True)
          (1): ReLU()
        )
        (1): Sequential(
          (0): Linear(in_features=65, out_features=5, bias=True)
        )
      )
      (V): Sequential(
        (0): Sequential(
          (0): Linear(in_features=65, out_features=65, bias=True)
          (1): ReLU()
        )
        (1): Sequential(
          (0): Linear(in_features=65, out_features=1, bias=True)
        )
      )
    )
    (1): RegressionHead(
      (main): Sequential(
        (0): Linear(in_features=64, out_features=64, bias=True)
        (1): ReLU()
      )
      (last): Linear(in_features=64, out_features=1, bias=True)
      (tanh): Tanh()
    )
  )
  (encoder): ModuleList(
    (0-1): 2 x FCEncoder(
      (act): ReLU()
      (init): Linear(in_features=163, out_features=128, bias=True)
      (main): Sequential(
        (0): Linear(in_features=128, out_features=128, bias=True)
        (1): ReLU()
        (2): Linear(in_features=128, out_features=64, bias=True)
        (3): ReLU()
      )
    )
  )
)
[2025-06-01 16:35:01][base_learner.py:360][INFO] [RANK0]: learner save ckpt in ./pdqn_exchange_cnot_250601_163450/ckpt/ckpt_best.pth.tar
[2025-06-01 16:35:21][base_learner.py:360][INFO] [RANK0]: === Training Iteration 0 Result ===
[2025-06-01 16:35:21][learner_hook.py:228][INFO] 
+-------+------------+----------------+------------+---------------------+
| Name  | cur_lr_avg | total_loss_avg | q_loss_avg | continuous_loss_avg |
+-------+------------+----------------+------------+---------------------+
| Value | 0.001000   | 8.652721       | 8.652721   | 0.000000            |
+-------+------------+----------------+------------+---------------------+
+-------+-------------+------------+--------------------+
| Name  | q_value_avg | reward_avg | target_q_value_avg |
+-------+-------------+------------+--------------------+
| Value | 0.000000    | -1.568713  | -0.029340          |
+-------+-------------+------------+--------------------+

[2025-06-01 16:35:21][base_learner.py:360][INFO] [RANK0]: learner save ckpt in ./pdqn_exchange_cnot_250601_163450/ckpt/iteration_0.pth.tar
[2025-06-01 16:45:45][base_learner.py:360][INFO] [RANK0]: === Training Iteration 100 Result ===
[2025-06-01 16:45:45][learner_hook.py:228][INFO] 
+-------+------------+----------------+------------+---------------------+
| Name  | cur_lr_avg | total_loss_avg | q_loss_avg | continuous_loss_avg |
+-------+------------+----------------+------------+---------------------+
| Value | 0.001000   | 16.000554      | 15.776123  | 0.224431            |
+-------+------------+----------------+------------+---------------------+
+-------+-------------+------------+--------------------+
| Name  | q_value_avg | reward_avg | target_q_value_avg |
+-------+-------------+------------+--------------------+
| Value | -0.044886   | 0.238731   | -0.046116          |
+-------+-------------+------------+--------------------+

[2025-06-01 16:49:48][base_learner.py:360][INFO] [RANK0]: learner save ckpt in ./pdqn_exchange_cnot_250601_163450/ckpt/iteration_141.pth.tar
