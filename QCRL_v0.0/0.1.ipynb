{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa57b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jax, jax.numpy as jnp\n",
    "# import math\n",
    "\n",
    "# from ex_operations import exchange_gate_nqubits\n",
    "# from ex_operations import exchange_generators\n",
    "\n",
    "# from gymnax.environments import environment, spaces\n",
    "# from flax import struct\n",
    "# import jax, jax.numpy as jnp\n",
    "# from functools import reduce\n",
    "# from typing import Tuple\n",
    "# from fw_target import U_circuit                                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e749610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-05-25 14:44:32,095:jax._src.xla_bridge:791: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 1.  Imports & environment\n",
    "# ------------------------------------------------------------\n",
    "import math, jax, jax.numpy as jnp\n",
    "from exchange_cnot_env import ExchangeCNOTEnv, EnvParams, NEIGHBORS   # your env file\n",
    "from fw_target          import U_circuit as TARGET_FULL               # (64,64)\n",
    "from ex_operations      import exchange_gate_nqubits                  # only for sanity\n",
    "# helper from your env file\n",
    "from exchange_cnot_env  import _fidelity                              # Frobenius-norm fidelity\n",
    "from exchange_cnot_env  import _block, LOGICAL                        # (9,9) block indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888aab70",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs[0:5] = [1. 0. 0. 0. 0.] done? -> False\n",
      "reward = -1.0 done? -> False\n"
     ]
    }
   ],
   "source": [
    "# # ----------------------------------------------------------------------\n",
    "# # 1.  Static problem data\n",
    "# # ----------------------------------------------------------------------\n",
    "# N_PHYS = 6\n",
    "# NEIGHBORS = jnp.array([[0, 1],\n",
    "#                        [1, 2],\n",
    "#                        [2, 3],\n",
    "#                        [3, 4],\n",
    "#                        [4, 5]], dtype=jnp.int32)   # 5 nearest pairs\n",
    "\n",
    "# # logical sub-space indices (0-based) ─ rows/cols \n",
    "# LOGICAL = jnp.array([9,10,12,17,18,20,33,34,36], dtype=jnp.int32)\n",
    "\n",
    "# # ----------  target unitary  -----------------------------------------\n",
    "# # IMPORT YOUR 64×64 TARGET HERE\n",
    "# from fw_target import U_circuit as TARGET_FULL           # (64,64) complex64\n",
    "# TARGET_BLOCK = TARGET_FULL[LOGICAL][:, LOGICAL]          # (9,9)\n",
    "# H_BASE = jnp.stack(\n",
    "#     [exchange_generators(N_PHYS, int(i), int(j)) for i, j in NEIGHBORS.tolist()],\n",
    "#     axis=0,                                             # shape (5, 64, 64)\n",
    "# )\n",
    "\n",
    "\n",
    "# # ----------------------------------------------------------------------\n",
    "# # 2.  Small helpers (JAX-friendly, no global state)\n",
    "# # ----------------------------------------------------------------------\n",
    "# def _block(U):                               # 9×9 logical block\n",
    "#     return U[LOGICAL][:, LOGICAL]\n",
    "\n",
    "\n",
    "# def _fidelity(A: jnp.ndarray, B: jnp.ndarray) -> jnp.float32:\n",
    "#     \"\"\"|⟨A,B⟩| / (‖A‖‖B‖)  ϵ [0,1]\"\"\"\n",
    "#     inner = jnp.vdot(A, B)\n",
    "#     return jnp.abs(inner) / (jnp.linalg.norm(A) * jnp.linalg.norm(B))\n",
    "\n",
    "\n",
    "# SEL = LOGICAL                                 # for the 27-element mask\n",
    "# ROWS, COLS = jnp.meshgrid(SEL, SEL, indexing=\"ij\")\n",
    "# MASK27 = (TARGET_FULL[ROWS, COLS] != 0)        # (9,9) boolean\n",
    "\n",
    "\n",
    "# # ----------------------------------------------------------------------\n",
    "# # 3.  Environment data-classes\n",
    "# # ----------------------------------------------------------------------\n",
    "# @struct.dataclass(frozen=True)\n",
    "# class EnvState:\n",
    "#     U:        jnp.ndarray\n",
    "#     step:     jnp.int32\n",
    "#     fid64:    jnp.float32     # last-computed full-matrix fidelity\n",
    "#     fid9:     jnp.float32     # last-computed block fidelity\n",
    "\n",
    "\n",
    "\n",
    "# @struct.dataclass\n",
    "# class EnvParams:\n",
    "#     max_depth: int = 18\n",
    "#     dense_obs: bool = False\n",
    "#     obs_mode: str = \"block\"   # \"block\" | \"full\" | \"both\"\n",
    "\n",
    "# # ----------------------------------------------------------------------\n",
    "# # 4.  Reward function (implements the 13 rules)\n",
    "# # ----------------------------------------------------------------------\n",
    "# def reward_fn(U_now, U_prev, step):\n",
    "#     \"\"\"\n",
    "#         Implements the 10 bullet-points exactly (vectorised & JIT-safe).\n",
    "#         Returns  (reward, done)\n",
    "#         1. For each step if the fidelity of the 64x64 is increased , +1 to the reward.\n",
    "#         2. For each step if the fidelity of the 64x64 is increased by .1, +5 reward.\n",
    "#         3. For each step if the fidelity of the 64x64 is increased by .2, +8 reward.\n",
    "#         4. For each step if the fidelity of the 9x9 is increased, +.5 to the reward.\n",
    "#         5. For each step if the fidelity of the 9x9 is increased by .1, +2 reward.\n",
    "#         6. For each step if the fidelity of the 9x9 is increased by .2, +3 reward.\n",
    "#         7. If the matrix matched 27 elements of the target in the following rows and columns [9,10,12,17,18,20,33,34,36], then +30 reward.\n",
    "#         8. For each step if the fidelity with the target matrix is reduced compared to the previous step, then -1 reward.\n",
    "#         9. For each step if the fidelity with the target matrix is reduced by .1 compared to the previous step, then -2 reward.\n",
    "#         10. For each step if the fidelity with the target matrix is reduced by .2 compared to the previous step, then -3 reward.\n",
    "#         11. For each step after the 10th step, step penalty of -1.\n",
    "#         12. If the matrix matches the entire 64d rows and columns of  the target matrix in the following indices [9,10,12,17,18,20,33,34,36], which would be 9*64*2 elements, +80 reward and exit.\n",
    "#         13. If the fidelity is greater than .99, +100 reward and exit.\n",
    "#     \"\"\"\n",
    "#     f64_now = _fidelity(U_now, TARGET_FULL)\n",
    "#     f9_now = _fidelity(_block(U_now), TARGET_BLOCK)\n",
    "#     f64_prev = _fidelity(U_prev, TARGET_FULL)\n",
    "#     f9_prev = _fidelity(_block(U_prev), TARGET_BLOCK)\n",
    "\n",
    "#     df64 = f64_now - f64_prev\n",
    "#     df9 = f9_now - f9_prev\n",
    "\n",
    "#     r = 0.0\n",
    "#     # 1-3\n",
    "#     r += jax.lax.select(df64 > 0, 1.0, 0.0)\n",
    "#     r += jax.lax.select(df64 >= 0.10, 5.0, 0.0)\n",
    "#     r += jax.lax.select(df64 >= 0.20, 8.0, 0.0)\n",
    "#     # 4-6\n",
    "#     r += jax.lax.select(df9 > 0, 0.5, 0.0)\n",
    "#     r += jax.lax.select(df9 >= 0.10, 2.0, 0.0)\n",
    "#     r += jax.lax.select(df9 >= 0.20, 3.0, 0.0)\n",
    "#     # 8-10 penalties\n",
    "#     r -= jax.lax.select(df64 < 0, 1.0, 0.0)\n",
    "#     r -= jax.lax.select(df64 <= -0.10, 2.0, 0.0)\n",
    "#     r -= jax.lax.select(df64 <= -0.20, 3.0, 0.0)\n",
    "#     # 11 step penalty\n",
    "#     r -= 0.25* step if step > 10 else 0.0\n",
    "\n",
    "#     # 7: 27-element exact match\n",
    "#     match27 = jnp.all(\n",
    "#         jnp.isclose(U_now[ROWS, COLS][MASK27],\n",
    "#                     TARGET_FULL[ROWS, COLS][MASK27],\n",
    "#                     atol=1e-6)\n",
    "#     )\n",
    "#     r += jax.lax.select(match27, 30.0, 0.0)\n",
    "\n",
    "#     # 12: all 9×64×2 real/imag entries of those rows identical\n",
    "#     full_match = jnp.all(jnp.isclose(U_now[SEL], TARGET_FULL[SEL], atol=1e-6))\n",
    "#     done_by_match = full_match\n",
    "#     r += jax.lax.select(done_by_match, 80.0, 0.0)\n",
    "\n",
    "#     # 13: fidelity ≥ .99\n",
    "#     done_by_fidelity = f64_now >= 0.99\n",
    "#     r += jax.lax.select(done_by_fidelity, 100.0, 0.0)\n",
    "\n",
    "#     done = jnp.logical_or(done_by_match, done_by_fidelity)\n",
    "#     return r.astype(jnp.float32), done, f64_now.astype(jnp.float32), f9_now.astype(jnp.float32)\n",
    "\n",
    "\n",
    "# # ----------------------------------------------------------------------\n",
    "# # 5.  The Gymnax environment\n",
    "# # ----------------------------------------------------------------------\n",
    "# class ExchangeCNOTEnv(environment.Environment):\n",
    "\n",
    "#     # ---- constructor -------------------------------------------------- #\n",
    "#     def __init__(self, params: EnvParams = EnvParams()):\n",
    "#         self._params = params\n",
    "#         super().__init__()\n",
    "        \n",
    "#         # sub-spaces reused by observation_space / action_space\n",
    "#         self._pair_space  = spaces.Discrete(NEIGHBORS.shape[0])             # 5\n",
    "#         self._angle_space = spaces.Box(\n",
    "#             low  = -jnp.ones(()),        # lower bound  scalar\n",
    "#             high =  jnp.ones(()),        # upper bound  scalar\n",
    "#             shape= (),                   # *scalar* continuous parameter p\n",
    "#             dtype=jnp.float32,\n",
    "#         )\n",
    "\n",
    "\n",
    "#     # ---- spaces ------------------------------------------------------- #\n",
    "#     # read-only accessor that mirrors the Gymnax interface\n",
    "#     @property\n",
    "#     def default_params(self) -> EnvParams:\n",
    "#         return self._params\n",
    "\n",
    "#     @property\n",
    "#     def observation_space(self):\n",
    "#         mode = self.default_params.obs_mode\n",
    "#         if mode == \"block\":\n",
    "#             dim = 9 * 9 * 2 + 1\n",
    "#         elif mode == \"full\":\n",
    "#             dim = 64 * 64 * 2 + 1\n",
    "#         elif mode == \"both\":\n",
    "#             dim = 64 * 64 * 2 + 9 * 9 * 2 + 1\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unknown obs_mode {mode}\")\n",
    "#         high = jnp.ones(dim, dtype=jnp.float32)\n",
    "#         return spaces.Box(-high, high)\n",
    "\n",
    "\n",
    "#     @property\n",
    "#     def action_space(self):\n",
    "#         \"\"\"Tuple (pair_id, p).\"\"\"\n",
    "#         return spaces.Tuple((self._pair_space, self._angle_space))\n",
    "\n",
    "#     # ---- helpers ------------------------------------------------------ #\n",
    "#     @staticmethod\n",
    "#     @jax.jit\n",
    "#     def _apply(U, pair_id, p):\n",
    "#         H = H_BASE[pair_id]                                # gather (JIT-safe)\n",
    "#         U_gate = jax.scipy.linalg.expm(-1j * jnp.pi * p * H)\n",
    "#         return U_gate @ U\n",
    "#     def _vec(self, U, step):\n",
    "#         mode = self.default_params.obs_mode\n",
    "#         parts = []\n",
    "#         if mode in (\"full\", \"both\"):\n",
    "#             parts += [U.real.flatten(), U.imag.flatten()]\n",
    "#         if mode in (\"block\", \"both\"):\n",
    "#             blk = _block(U)\n",
    "#             parts += [blk.real.flatten(), blk.imag.flatten()]\n",
    "#         parts += [jnp.array([step], dtype=jnp.float32)]\n",
    "#         return jnp.concatenate(parts).astype(jnp.float32)\n",
    "\n",
    "#     # ---- reset -------------------------------------------------------- #\n",
    "#     def reset(self, key: jax.random.PRNGKey,\n",
    "#               params: EnvParams | None = None) -> Tuple[EnvState, jnp.ndarray]:\n",
    "#         p = self.default_params if params is None else params\n",
    "#         U0 = jnp.eye(2 ** N_PHYS, dtype=jnp.complex64)\n",
    "#         U0 = jnp.eye(2 ** N_PHYS, dtype=jnp.complex64)\n",
    "#         phase = jnp.vdot(U0, TARGET_FULL)/jnp.abs(jnp.vdot(U0, TARGET_FULL))\n",
    "#         fid64_0 = _fidelity(U0*phase.conj(), TARGET_FULL)\n",
    "#         fid9_0 = _fidelity(_block(U0), TARGET_BLOCK)\n",
    "#         obs0 = self._vec(U0, 0)\n",
    "#         return EnvState(U0, 0, fid64_0, fid9_0), obs0\n",
    "\n",
    "#     # ---- step --------------------------------------------------------- #\n",
    "#     def step(self, key: jax.random.PRNGKey, state: EnvState, action,\n",
    "#              params: EnvParams | None = None):\n",
    "#         \"\"\"action = (pair_id, array([p]))\"\"\"\n",
    "#         p_cfg = self.default_params if params is None else params\n",
    "\n",
    "#         pair_id, p_val = action               # p_val is length-1 array\n",
    "#         p_scalar = jnp.squeeze(p_val)            \n",
    "\n",
    "#         U_next = self._apply(state.U, pair_id, p_scalar)\n",
    "#         step_no = state.step + 1\n",
    "\n",
    "#         # reward & termination\n",
    "#         r, done_intrinsic, f64, f9 = reward_fn(U_next, state.U, step_no)\n",
    "#         done = jnp.logical_or(done_intrinsic, step_no == p_cfg.max_depth)\n",
    "\n",
    "#         obs = self._vec(U_next, step_no)\n",
    "#         new_state = EnvState(U_next, step_no, f64, f9)\n",
    "#         return new_state, obs, r, done, {}\n",
    "\n",
    "# # ----------------------------------------------------------------------\n",
    "# # 6.  Smoke-test\n",
    "# # ----------------------------------------------------------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     env = ExchangeCNOTEnv(EnvParams(max_depth=18, obs_mode=\"both\"))\n",
    "#     key = jax.random.PRNGKey(0)\n",
    "\n",
    "#     state, obs = env.reset(key)\n",
    "#     print(\"obs[0:5] =\", obs[:5], \"done? ->\", False)\n",
    "\n",
    "#     # random action: choose pair 2, p = 0.3\n",
    "#     action = (2, jnp.array([0.3], dtype=jnp.float32))\n",
    "#     state, obs, r, done, _ = env.step(key, state, action)\n",
    "#     print(\"reward =\", float(r), \"done? ->\", bool(done))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ea4fe5",
   "metadata": {},
   "source": [
    "## Unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d12acf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====  Fong–Wandzura 22-pulse unit test  =====\n",
      "step 01  pair_id=3  p= 1.695913  reward=-1.000  fid64=0.229334\n",
      "step 02  pair_id=4  p= 0.108173  reward=-1.000  fid64=0.223945\n",
      "step 03  pair_id=2  p= 0.500000  reward=-1.000  fid64=0.177044\n",
      "step 04  pair_id=3  p= 1.000000  reward=-1.000  fid64=0.110696\n",
      "step 05  pair_id=2  p=-0.500000  reward= 1.500  fid64=0.114028\n",
      "step 06  pair_id=4  p=-0.500000  reward= 1.000  fid64=0.127438\n",
      "step 07  pair_id=1  p= 1.000000  reward= 8.500  fid64=0.290135\n",
      "step 08  pair_id=3  p=-0.500000  reward= 1.000  fid64=0.291383\n",
      "step 09  pair_id=2  p=-0.500000  reward=-1.000  fid64=0.263663\n",
      "step 10  pair_id=4  p= 1.000000  reward= 6.500  fid64=0.334522\n",
      "step 11  pair_id=1  p=-0.500000  reward=-5.750  fid64=0.221102\n",
      "step 12  pair_id=3  p= 0.500000  reward=-1.500  fid64=0.275630\n",
      "step 13  pair_id=2  p=-0.500000  reward=-4.250  fid64=0.263796\n",
      "step 14  pair_id=4  p= 1.000000  reward=-4.500  fid64=0.224025\n",
      "step 15  pair_id=1  p= 1.000000  reward= 15.750  fid64=0.448051\n",
      "step 16  pair_id=3  p=-0.500000  reward=-5.000  fid64=0.370208\n",
      "step 17  pair_id=2  p=-0.500000  reward=-5.250  fid64=0.276280\n",
      "step 18  pair_id=4  p=-0.500000  reward=-5.000  fid64=0.263254\n",
      "step 19  pair_id=3  p= 1.000000  reward= 3.750  fid64=0.377843\n",
      "step 20  pair_id=2  p= 0.500000  reward= 1.500  fid64=0.477938\n",
      "step 21  pair_id=4  p= 0.891827  reward= 14.250  fid64=0.917337\n",
      "step 22  pair_id=3  p= 0.304087  reward= 208.000  fid64=1.000000\n",
      "*** episode terminated after 22 steps ***\n",
      "\n",
      "Final fidelities:\n",
      "  ‖U_final − U_target‖_F  (64×64)  = -1.19e-07\n",
      "  DFS-block fidelity (9×9)          = 1.000000\n",
      "✅  FW sequence reproduces the target gate exactly.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2.  Fong-Wandzura 22-pulse specification (0-based qubit ids)\n",
    "# ------------------------------------------------------------\n",
    "p1 = math.acos(-1 / math.sqrt(3)) / math.pi     # ≈ 0.696…\n",
    "p2 = math.asin( 1 /             3) / math.pi    # ≈ 0.108…\n",
    "\n",
    "gate_specs = [\n",
    "    ( 1+p1,  [3,4] ),\n",
    "    # ( p1,    [3,4] ),\n",
    "    ( p2,    [4,5] ),\n",
    "    ( 0.5,   [2,3] ),\n",
    "    ( 1.0,   [3,4] ),\n",
    "    (-0.5,   [2,3] ),\n",
    "    (-0.5,   [4,5] ),\n",
    "    ( 1.0,   [1,2] ),\n",
    "    (-0.5,   [3,4] ),\n",
    "    (-0.5,   [2,3] ),\n",
    "    ( 1.0,   [4,5] ),\n",
    "    (-0.5,   [1,2] ),\n",
    "    ( 0.5,   [3,4] ),\n",
    "    (-0.5,   [2,3] ),\n",
    "    ( 1.0,   [4,5] ),\n",
    "    ( 1.0,   [1,2] ),\n",
    "    (-0.5,   [3,4] ),\n",
    "    (-0.5,   [2,3] ),\n",
    "    (-0.5,   [4,5] ),\n",
    "    ( 1.0,   [3,4] ),\n",
    "    ( 0.5,   [2,3] ),\n",
    "    ( 1-p2,  [4,5] ),\n",
    "    # ( -p1,   [3,4] ),\n",
    "    ( 1-p1,  [3,4] ),\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3.  Utility: map (i,j) → pair_id in NEIGHBORS (order-agnostic)\n",
    "# ------------------------------------------------------------\n",
    "def pair_to_id(i: int, j: int) -> int:\n",
    "    \"\"\"Return k such that set(NEIGHBORS[k]) == {i,j}.\"\"\"\n",
    "    a, b = sorted((i, j))                       # unordered → ordered\n",
    "    # Boolean mask over rows of NEIGHBORS\n",
    "    mask = jnp.all(NEIGHBORS == jnp.array([a, b]), axis=1)\n",
    "    # indices where mask==True   (at most one for a proper table)\n",
    "    idx_arr = jnp.nonzero(mask, size=1, fill_value=-1)[0]\n",
    "    idx     = int(idx_arr.item())               # ← convert scalar array → int\n",
    "    if idx == -1:\n",
    "        raise ValueError(f\"Pair {(i, j)} not present in NEIGHBORS.\")\n",
    "    return idx\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.  Build the action list in env format\n",
    "# ------------------------------------------------------------\n",
    "actions = [\n",
    "    ( pair_to_id(i, j), jnp.array([p], dtype=jnp.float32) )\n",
    "    for p, (i, j) in gate_specs\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5.  Run one deterministic episode\n",
    "# ------------------------------------------------------------\n",
    "env   = ExchangeCNOTEnv(EnvParams(max_depth=len(actions)))\n",
    "key   = jax.random.PRNGKey(42)\n",
    "state, obs = env.reset(key)\n",
    "\n",
    "print(\"=====  Fong–Wandzura 22-pulse unit test  =====\")\n",
    "for t, act in enumerate(actions, start=1):\n",
    "    key, sub = jax.random.split(key)\n",
    "    state, obs, r, done, _ = env.step(sub, state, act)\n",
    "\n",
    "    pair_id = act[0]\n",
    "    p_val   = act[1].item()       # ← scalar\n",
    "    reward  = r.item()            # ← scalar\n",
    "    fid64   = state.fid64.item()  # ← scalar\n",
    "\n",
    "    print(f\"step {t:02d}  pair_id={pair_id}  p={p_val: .6f}  \"\n",
    "          f\"reward={reward: .3f}  fid64={fid64:.6f}\")\n",
    "    if done:\n",
    "        print(f\"*** episode terminated after {t} steps ***\")\n",
    "        break\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6.  Post-mortem: check full-matrix fidelity & block fidelity\n",
    "# ------------------------------------------------------------\n",
    "phase  = jnp.vdot(state.U, TARGET_FULL)\n",
    "phase /= jnp.abs(phase)                    # remove global phase\n",
    "fid64  = _fidelity(state.U*phase.conj(), TARGET_FULL)\n",
    "fid9   = _fidelity(_block(state.U), _block(TARGET_FULL))\n",
    "\n",
    "print(\"\\nFinal fidelities:\")\n",
    "print(f\"  ‖U_final − U_target‖_F  (64×64)  = {1 - float(fid64):.2e}\")\n",
    "print(f\"  DFS-block fidelity (9×9)          = {float(fid9):.6f}\")\n",
    "\n",
    "assert jnp.isclose(fid64, 1.0, atol=1e-6), \"Full 64×64 fidelity < 0.999999\"\n",
    "assert jnp.isclose(fid9 , 1.0, atol=1e-6), \"Logical-block fidelity < 0.999999\"\n",
    "print(\"✅  FW sequence reproduces the target gate exactly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82722c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-05-25 15:24:07,387:jax._src.xla_bridge:791: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m env           \u001b[38;5;241m=\u001b[39m FlattenObservationWrapper(base_env)           \u001b[38;5;66;03m# obs → 1-D\u001b[39;00m\n\u001b[1;32m     45\u001b[0m env           \u001b[38;5;241m=\u001b[39m LogWrapper(env)                               \u001b[38;5;66;03m# episodic stats\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m disc_dim \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mspaces[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn           \u001b[38;5;66;03m# == 5 neighbour pairs\u001b[39;00m\n\u001b[1;32m     48\u001b[0m obs_shape \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space(env_params)\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# 2.  Policy / value network\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------------------------\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# train_exchange_cnot.py\n",
    "# Search for shorter exchange–only CNOT circuits with PPO (purejaxrl style)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "import jax, jax.numpy as jnp\n",
    "from functools import partial\n",
    "\n",
    "# --- local modules you already uploaded -------------------------------------\n",
    "from exchange_cnot_env import ExchangeCNOTEnv, EnvParams         # the env\n",
    "from ppo_qcrl import ActorCritic                                 # model\n",
    "from purejaxrl.purejaxrl.wrappers import LogWrapper, FlattenObservationWrapper       # purejaxrl\n",
    "\n",
    "import optax, distrax, numpy as np\n",
    "from flax.training.train_state import TrainState\n",
    "from flax.linen.initializers import constant, orthogonal\n",
    "import gymnax                                                     # just for spaces helpers\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 0.  Config\n",
    "# ----------------------------------------------------------------------------\n",
    "config = dict(\n",
    "    TOTAL_TIMESTEPS = 1_000_000,     # feel free to raise – keeps compilation tolerable\n",
    "    NUM_ENVS        = 16,            # vectorised environments\n",
    "    NUM_STEPS       = 128,           # rollout length\n",
    "    UPDATE_EPOCHS   = 4,\n",
    "    NUM_MINIBATCHES = 8,\n",
    "    LR              = 3e-4,\n",
    "    ACTOR_ACTIVATION = \"tanh\",       # \"relu\" also ok\n",
    "    GAMMA           = 0.995,\n",
    "    GAE_LAMBDA      = 0.95,\n",
    "    CLIP_EPS        = 0.2,\n",
    "    ENT_COEF        = 1e-2,\n",
    "    VF_COEF         = 0.5,\n",
    "    MAX_GRAD_NORM   = 0.5,\n",
    "    ANNEAL_LR       = True,\n",
    "    DEBUG           = True,          # prints episodic return every few seconds\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.  Environment (with wrappers) & spaces helpers\n",
    "# ----------------------------------------------------------------------------\n",
    "base_env      = ExchangeCNOTEnv(EnvParams(max_depth=18, obs_mode=\"block\"))\n",
    "env_params    = base_env.default_params\n",
    "env           = FlattenObservationWrapper(base_env)           # obs → 1-D\n",
    "env           = LogWrapper(env)                               # episodic stats\n",
    "\n",
    "disc_dim = env.action_space(env_params).spaces[0].n           # == 5 neighbour pairs\n",
    "obs_shape = env.observation_space(env_params).shape\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.  Policy / value network\n",
    "# ----------------------------------------------------------------------------\n",
    "class AC(ActorCritic):\n",
    "    disc_dim: int = disc_dim\n",
    "    activation: str = config[\"ACTOR_ACTIVATION\"]\n",
    "\n",
    "network = AC()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3.  Training utilities\n",
    "# ----------------------------------------------------------------------------\n",
    "def linear_schedule(count, base_lr=config[\"LR\"], total_updates=None):\n",
    "    \"\"\"\n",
    "    Linear LR decay identical to Stable-Baselines3.\n",
    "    \"\"\"\n",
    "    frac = 1.0 - count / total_updates if total_updates else 1.0\n",
    "    return base_lr * frac\n",
    "\n",
    "def make_optimizer(total_updates):\n",
    "    if config[\"ANNEAL_LR\"]:\n",
    "        sched = partial(linear_schedule, total_updates=total_updates)\n",
    "        tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "            optax.adam(learning_rate=sched, eps=1e-5)\n",
    "        )\n",
    "    else:\n",
    "        tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "            optax.adam(config[\"LR\"], eps=1e-5)\n",
    "        )\n",
    "    return tx\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4.  Main training function (pure-JAX)\n",
    "# ----------------------------------------------------------------------------\n",
    "def make_ppo_train(config):\n",
    "    total_updates   = (config[\"TOTAL_TIMESTEPS\"] //\n",
    "                       config[\"NUM_STEPS\"] //\n",
    "                       config[\"NUM_ENVS\"])\n",
    "    minibatch_size  = (config[\"NUM_ENVS\"] * config[\"NUM_STEPS\"] //\n",
    "                       config[\"NUM_MINIBATCHES\"])\n",
    "    tx              = make_optimizer(total_updates)\n",
    "\n",
    "    def train(rng):\n",
    "        # -- network init -----------------------------------------------------\n",
    "        rng, net_key = jax.random.split(rng)\n",
    "        params  = network.init(net_key, jnp.zeros(obs_shape))\n",
    "        state   = TrainState.create(apply_fn=network.apply, params=params, tx=tx)\n",
    "\n",
    "        # -- env init ---------------------------------------------------------\n",
    "        rng, env_key = jax.random.split(rng)\n",
    "        keys   = jax.random.split(env_key, config[\"NUM_ENVS\"])\n",
    "        obs,   env_state = jax.vmap(env.reset, in_axes=(0,None))(keys, env_params)\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # vmap helpers for multi-env rollout\n",
    "        # --------------------------------------------------------------------\n",
    "        Transition = gymnax.collector.Transition  # tiny struct from purejaxrl >=0.3\n",
    "        def policy_step(state, obs, rng):\n",
    "            \"\"\"\n",
    "            One policy inference step – returns action, value, log-prob.\n",
    "            \"\"\"\n",
    "            rng, sample_key = jax.random.split(rng)\n",
    "            pi, value = network.apply(state.params, obs)\n",
    "            action    = pi.sample(seed=sample_key)\n",
    "            logp      = pi.log_prob(action)\n",
    "            return rng, action, value, logp\n",
    "\n",
    "        def env_step(rng, env_state, action):\n",
    "            rng, step_key = jax.random.split(rng)\n",
    "            new_state, new_obs, reward, done, info = env.step(\n",
    "                step_key, env_state, action, env_params\n",
    "            )\n",
    "            return rng, new_state, new_obs, reward, done, info\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # Main loop (jax.lax.scan over updates)\n",
    "        # --------------------------------------------------------------------\n",
    "        def update_loop(carry, unused_t):\n",
    "            train_state, env_state, last_obs, rng = carry\n",
    "            # ===== COLLECT TRAJECTORY =====\n",
    "            def rollout_step(carry, t):\n",
    "                rng, env_state, obs = carry\n",
    "                rng, act, val, logp = jax.vmap(policy_step, in_axes=(None,0,0))(\n",
    "                    train_state, obs, jax.random.split(rng, config[\"NUM_ENVS\"])\n",
    "                )\n",
    "                rng, env_state, next_obs, rew, done, info = jax.vmap(env_step, in_axes=(0,0,0))(\n",
    "                    jax.random.split(rng, config[\"NUM_ENVS\"]), env_state, act\n",
    "                )\n",
    "                trans = Transition(obs, act, rew, done, val, logp)\n",
    "                return (rng, env_state, next_obs), trans\n",
    "\n",
    "            (rng, env_state, next_obs), traj = jax.lax.scan(\n",
    "                rollout_step,\n",
    "                (rng, env_state, obs),\n",
    "                None,\n",
    "                length=config[\"NUM_STEPS\"]\n",
    "            )\n",
    "\n",
    "            # ===== GAE / target value =====\n",
    "            _, last_val = jax.vmap(policy_step, in_axes=(None,0,0))(\n",
    "                train_state, next_obs,\n",
    "                jax.random.split(rng, config[\"NUM_ENVS\"])\n",
    "            )\n",
    "\n",
    "            def _gae(carry, transition):\n",
    "                gae, next_val = carry\n",
    "                delta = transition.reward + config[\"GAMMA\"] * next_val * (1.0 - transition.done) - transition.value\n",
    "                gae   = delta + config[\"GAMMA\"] * config[\"GAE_LAMBDA\"] * (1.0 - transition.done) * gae\n",
    "                return (gae, transition.value), gae\n",
    "\n",
    "            (_, _), advantages = jax.lax.scan(\n",
    "                _gae, (jnp.zeros_like(last_val), last_val), traj, reverse=True\n",
    "            )\n",
    "            targets = advantages + traj.value\n",
    "\n",
    "            # ===== SHUFFLE / MINIBATCH SGD =====\n",
    "            batch_size = config[\"NUM_ENVS\"] * config[\"NUM_STEPS\"]\n",
    "            flat = gymnax.collector.flatten_batch((traj, advantages, targets))\n",
    "            permutation = jax.random.permutation(rng, batch_size)\n",
    "            shuffled = jax.tree_util.tree_map(lambda x: jnp.take(x, permutation, axis=0), flat)\n",
    "\n",
    "            def sgd_epoch(state, unused_e):\n",
    "                def minibatch_update(state, mb_idx):\n",
    "                    mb = jax.tree_util.tree_map(\n",
    "                        lambda x: jnp.take(x, mb_idx, axis=0), shuffled\n",
    "                    )\n",
    "\n",
    "                    def loss_fn(params):\n",
    "                        pi, values = network.apply(params, mb.obs)\n",
    "                        logp = pi.log_prob(mb.action)\n",
    "                        # actor loss\n",
    "                        ratio = jnp.exp(logp - mb.log_prob)\n",
    "                        adv   = (mb.advantages - mb.advantages.mean()) / (mb.advantages.std() + 1e-8)\n",
    "                        loss_actor = -jnp.mean(jnp.minimum(\n",
    "                            ratio * adv,\n",
    "                            jnp.clip(ratio, 1.0 - config[\"CLIP_EPS\"], 1.0 + config[\"CLIP_EPS\"]) * adv\n",
    "                        ))\n",
    "                        # critic loss\n",
    "                        v_pred_clipped = mb.value + (values - mb.value).clip(-config[\"CLIP_EPS\"], config[\"CLIP_EPS\"])\n",
    "                        v_loss = 0.5 * jnp.mean(jnp.maximum(\n",
    "                            (values - mb.targets)**2,\n",
    "                            (v_pred_clipped - mb.targets)**2\n",
    "                        ))\n",
    "                        # entropy bonus\n",
    "                        entropy = jnp.mean(pi.entropy())\n",
    "                        loss = loss_actor + config[\"VF_COEF\"] * v_loss - config[\"ENT_COEF\"] * entropy\n",
    "                        return loss, (loss_actor, v_loss, entropy)\n",
    "\n",
    "                    grads_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "                    (loss, aux), grads = grads_fn(state.params)\n",
    "                    state = state.apply_gradients(grads=grads)\n",
    "                    return state, aux\n",
    "\n",
    "                # build minibatch indices\n",
    "                idx = jnp.arange(batch_size).reshape(config[\"NUM_MINIBATCHES\"], -1)\n",
    "                state, metrics = jax.lax.scan(minibatch_update, state, idx)\n",
    "                return state, metrics\n",
    "\n",
    "            train_state, _ = jax.lax.scan(sgd_epoch, train_state, None, length=config[\"UPDATE_EPOCHS\"])\n",
    "\n",
    "            # OPTIONAL: simple callback\n",
    "            if config[\"DEBUG\"]:\n",
    "                def _print(info):\n",
    "                    # log reward of *finished* episodes only\n",
    "                    returns = info[\"returned_episode_returns\"][info[\"returned_episode\"]]\n",
    "                    steps   = info[\"timestep\"][info[\"returned_episode\"]] * config[\"NUM_ENVS\"]\n",
    "                    for r, s in zip(returns.tolist(), steps.tolist()):\n",
    "                        print(f\"Step {s:>7} | episodic return: {r:8.3f}\")\n",
    "                jax.debug.callback(_print, traj.info)\n",
    "\n",
    "            carry_out = (train_state, env_state, next_obs, rng)\n",
    "            return carry_out, {}\n",
    "\n",
    "        # ---- run -----------------------------------------------------------\n",
    "        carry = (state, env_state, obs, rng)\n",
    "        carry, _ = jax.lax.scan(update_loop, carry, None, length=total_updates)\n",
    "        return carry[0]   # trained TrainState\n",
    "\n",
    "    # jit once outside of the call site\n",
    "    return jax.jit(train, donate_argnums=(0,))\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5.  Launch\n",
    "# ----------------------------------------------------------------------------\n",
    "rng = jax.random.PRNGKey(0)\n",
    "train_fn = make_ppo_train(config)\n",
    "final_state = train_fn(rng)\n",
    "\n",
    "print(\"\\nTraining finished – parameters in `final_state.params`\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
