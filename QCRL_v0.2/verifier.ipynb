{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182e7dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ding.entry import serial_pipeline\n",
    "from config import main_config, create_config\n",
    "\n",
    "serial_pipeline([main_config, create_config], seed=42, max_env_step=25000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bc8c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BEST-PATH SEQUENCE  (iteration_12.pth.tar) ===\n",
      "\n",
      "Step  1: pair = 0,  p = -0.0144\n",
      "Step  2: pair = 1,  p = -0.0152\n",
      "Step  3: pair = 3,  p = -0.0125\n",
      "Step  4: pair = 2,  p = -0.0159\n",
      "Step  5: pair = 1,  p = -0.0174\n",
      "Step  6: pair = 2,  p = -0.0156\n",
      "Step  7: pair = 0,  p = -0.0194\n",
      "Step  8: pair = 3,  p = -0.0199\n",
      "Step  9: pair = 2,  p = -0.0218\n",
      "Step 10: pair = 0,  p = -0.0222\n",
      "Step 11: pair = 2,  p = -0.0217\n",
      "Step 12: pair = 3,  p = -0.0238\n",
      "Step 13: pair = 3,  p = -0.0257\n",
      "Step 14: pair = 2,  p = -0.0251\n",
      "Step 15: pair = 1,  p = -0.0237\n",
      "Step 16: pair = 2,  p = -0.0213\n",
      "Step 17: pair = 3,  p = -0.0223\n",
      "Step 18: pair = 3,  p = -0.0226\n",
      "\n",
      "Final metrics:\n",
      " 64×64 fidelity    : nan\n",
      "  9×9 block fidelity: nan\n",
      " Total return       : -52.680750\n",
      "\n",
      "=== BEST-PATH SEQUENCE  (ckpt_best.pth.tar) ===\n",
      "\n",
      "Step  1: pair = 2,  p = +0.0414\n",
      "Step  2: pair = 1,  p = +0.0424\n",
      "Step  3: pair = 4,  p = +0.0440\n",
      "Step  4: pair = 0,  p = +0.0434\n",
      "Step  5: pair = 3,  p = +0.0406\n",
      "Step  6: pair = 0,  p = +0.0454\n",
      "Step  7: pair = 4,  p = +0.0452\n",
      "Step  8: pair = 4,  p = +0.0503\n",
      "Step  9: pair = 0,  p = +0.0515\n",
      "Step 10: pair = 4,  p = +0.0494\n",
      "Step 11: pair = 3,  p = +0.0537\n",
      "Step 12: pair = 1,  p = +0.0502\n",
      "Step 13: pair = 4,  p = +0.0526\n",
      "Step 14: pair = 3,  p = +0.0548\n",
      "Step 15: pair = 0,  p = +0.0536\n",
      "Step 16: pair = 3,  p = +0.0545\n",
      "Step 17: pair = 4,  p = +0.0524\n",
      "Step 18: pair = 2,  p = +0.0561\n",
      "\n",
      "Final metrics:\n",
      " 64×64 fidelity    : 0.080210\n",
      "  9×9 block fidelity: 0.159033\n",
      " Total return       : -49.528942\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ───────────────────────── manual_inference.py ──────────────────────────\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "# 1)  DI-engine PDQN policy\n",
    "from ding.policy.pdqn import PDQNPolicy          # or pdqn_command\n",
    "# 2)  Your custom environment\n",
    "from exch_gym_env import ExchangeCNOTEnvDI\n",
    "\n",
    "# ─── change these two paths as needed ───────────────────────────────────\n",
    "CKPT1 = \"pdqn_exchange_cnot_250605_010501/ckpt/iteration_12.pth.tar\"\n",
    "CKPT2 = \"pdqn_exchange_cnot_250605_010501/ckpt/ckpt_best.pth.tar\"\n",
    "# ------------------------------------------------------------------------\n",
    "\n",
    "def run_checkpoint(ckpt_path: str) -> None:\n",
    "    if not os.path.isfile(ckpt_path):\n",
    "        raise FileNotFoundError(ckpt_path)\n",
    "\n",
    "    # -------- build a *minimal* PDQN policy object ----------------------\n",
    "    cfg = edict(\n",
    "        type=\"pdqn\",\n",
    "        cuda=torch.cuda.is_available(),\n",
    "        on_policy=False,\n",
    "        model=dict(\n",
    "            obs_shape=168,                      # <-- keep same as training\n",
    "            action_shape=edict(\n",
    "                action_type_shape=5,\n",
    "                action_args_shape=1,\n",
    "                encoder_hidden_size_list=[256, 256, 256],\n",
    "            ),\n",
    "        ),\n",
    "        collect=dict(n_sample=0),\n",
    "        other=dict(replay_buffer=dict(replay_buffer_size=1)),\n",
    "        model_load_mode=\"ckpt\",\n",
    "        load_path=ckpt_path,\n",
    "    )\n",
    "\n",
    "    policy  = PDQNPolicy(cfg, enable_field=[\"eval\"])\n",
    "    device  = torch.device(\"cuda\" if cfg.cuda else \"cpu\")\n",
    "\n",
    "    # -------- load weights ---------------------------------------------\n",
    "    state = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "    policy._model.load_state_dict(state[\"model\"], strict=False)\n",
    "    if hasattr(policy, \"_target_model\"):\n",
    "        policy._target_model.load_state_dict(state[\"model\"], strict=False)\n",
    "\n",
    "    model = policy._eval_model      # wrapped with HybridArgmaxSampleWrapper\n",
    "    model.eval()                    # no dropout / batch-norm\n",
    "    model.to(device)\n",
    "\n",
    "    # -------- evaluation episode ---------------------------------------\n",
    "    env   = ExchangeCNOTEnvDI(use_act_scale=True)\n",
    "    obs   = env.reset()                                # numpy array (168,)\n",
    "    seq   = []                                         # [(pair_idx, p), …]\n",
    "    total = 0.0\n",
    "    done  = False\n",
    "\n",
    "    while not done and len(seq) < env.max_depth:\n",
    "        # --- observation tensor (shape 1 × N) --------------------------\n",
    "        obs_t = torch.as_tensor(obs, dtype=torch.float32,\n",
    "                                device=device).unsqueeze(0)\n",
    "\n",
    "        # --- writable action-mask tensor (shape 1 × 5) -----------------\n",
    "        mask_np = np.asarray(env.valid_mask, dtype=np.float32).copy()\n",
    "        mask_t  = torch.from_numpy(mask_np).to(device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 1) continuous argument\n",
    "            cont_out    = model.forward(obs_t, mode=\"compute_continuous\")\n",
    "            action_args = cont_out[\"action_args\"]               # (1, 1)\n",
    "\n",
    "            # 2) discrete choice with mask\n",
    "            inputs  = {\n",
    "                \"state\":       obs_t,\n",
    "                \"action_args\": action_args,\n",
    "                \"action_mask\": mask_t,          # the crucial piece\n",
    "            }\n",
    "            dis_out = model.forward(inputs, mode=\"compute_discrete\")\n",
    "            logits = dis_out[\"logit\"]             # shape: (1, 5)\n",
    "            probs  = torch.softmax(logits, dim=-1)\n",
    "            pair_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "            p_value  = float(action_args[0])\n",
    "\n",
    "        act = {\"action_type\": torch.tensor([pair_idx]), \"action_args\": torch.tensor([p_value])}\n",
    "        pair_idx  = int(act[\"action_type\"][0])\n",
    "        p_value   = float(act[\"action_args\"][0])\n",
    "\n",
    "        seq.append((pair_idx, p_value))\n",
    "        obs, reward, done, info = env.step((pair_idx, p_value))\n",
    "        total += reward\n",
    "\n",
    "    # -------- print results --------------------------------------------\n",
    "    print(f\"\\n=== BEST-PATH SEQUENCE  ({os.path.basename(ckpt_path)}) ===\\n\")\n",
    "    for t, (idx, p) in enumerate(seq, 1):\n",
    "        print(f\"Step {t:2d}: pair = {idx},  p = {p:+.4f}\")\n",
    "\n",
    "    print(\"\\nFinal metrics:\")\n",
    "    print(f\" 64×64 fidelity    : {info.get('fid64', np.nan):.6f}\")\n",
    "    print(f\"  9×9 block fidelity: {info.get('fid9',  np.nan):.6f}\")\n",
    "    print(f\" Total return       : {total:.6f}\")\n",
    "\n",
    "# ─── run the two checkpoints -------------------------------------------\n",
    "run_checkpoint(CKPT1)\n",
    "run_checkpoint(CKPT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cabeac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schiffer98/QCRL/.venv/lib/python3.10/site-packages/treevalue/tree/integration/torch.py:23: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  register_for_torch(TreeValue)\n",
      "/home/schiffer98/QCRL/.venv/lib/python3.10/site-packages/treevalue/tree/integration/torch.py:24: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  register_for_torch(FastTreeValue)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replay of fw_target gate list:\n",
      "step |  pair  |      p       |  reward   | fidelity\n",
      "-----+--------+--------------+-----------+----------\n",
      "[debug] step 1  raw_reward=13.0\n",
      "   1 | 3-4  | +1.695913 |   +13.000 | 0.067011\n",
      "[debug] step 2  raw_reward=5.0\n",
      "   2 | 4-5  | +0.108173 |    +5.000 | 0.064629\n",
      "[debug] step 3  raw_reward=-3.0\n",
      "   3 | 2-3  | +0.500000 |    -3.000 | 0.046148\n",
      "[debug] step 4  raw_reward=-3.0\n",
      "   4 | 3-4  | +1.000000 |    -3.000 | 0.027403\n",
      "[debug] step 5  raw_reward=15.0\n",
      "   5 | 2-3  | -0.500000 |   +15.000 | 0.028145\n",
      "[debug] step 6  raw_reward=-1.0\n",
      "   6 | 4-5  | -0.500000 |    -1.000 | 0.031295\n",
      "[debug] step 7  raw_reward=15.5\n",
      "   7 | 1-2  | +1.000000 |   +15.500 | 0.097912\n",
      "[debug] step 8  raw_reward=3.0\n",
      "   8 | 3-4  | -0.500000 |    +3.000 | 0.098648\n",
      "[debug] step 9  raw_reward=-6.0\n",
      "   9 | 2-3  | -0.500000 |    -6.000 | 0.083570\n",
      "[debug] step 10  raw_reward=12.33772233983162\n",
      "  10 | 4-5  | +1.000000 |   +12.338 | 0.125226\n",
      "[debug] step 11  raw_reward=-6.3166247903554\n",
      "  11 | 1-2  | -0.500000 |    -6.317 | 0.063352\n",
      "[debug] step 12  raw_reward=4.035898384862246\n",
      "  12 | 3-4  | +0.500000 |    +4.036 | 0.089911\n",
      "[debug] step 13  raw_reward=-6.60555127546399\n",
      "  13 | 2-3  | -0.500000 |    -6.606 | 0.083674\n",
      "[debug] step 14  raw_reward=-2.7416573867739413\n",
      "  14 | 4-5  | +1.000000 |    -2.742 | 0.064606\n",
      "[debug] step 15  raw_reward=9.627016653792584\n",
      "  15 | 1-2  | +1.000000 |    +9.627 | 0.212291\n",
      "[debug] step 16  raw_reward=-7.0\n",
      "  16 | 3-4  | -0.500000 |    -7.000 | 0.149831\n",
      "[debug] step 17  raw_reward=-7.123105625617661\n",
      "  17 | 2-3  | -0.500000 |    -7.123 | 0.090261\n",
      "[debug] step 18  raw_reward=-6.742640687119285\n",
      "  18 | 4-5  | -0.500000 |    -6.743 | 0.083292\n",
      "[debug] step 19  raw_reward=-4.858898943540674\n",
      "  19 | 3-4  | +1.000000 |    -4.859 | 0.155397\n",
      "[debug] step 20  raw_reward=-0.9721359549995796\n",
      "  20 | 2-3  | +0.500000 |    -0.972 | 0.239318\n",
      "[debug] step 21  raw_reward=2.91742430504416\n",
      "  21 | 4-5  | +0.891827 |    +2.917 | 0.840193\n",
      "[debug] step 22  raw_reward=105.80958424017658\n",
      "  22 | 3-4  | +0.304087 |  +105.810 | 0.995401\n",
      "\n",
      "Episode terminated early by reward logic at step 22.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Replay the forward-target gate list and print reward + fidelity each step.\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from exch_gym_env import ExchangeCNOTEnvDI, _fidelity    # env + helper\n",
    "from fw_target       import gate_specs, U_circuit        # sequence + target\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# The environment hard-codes five nearest-neighbour pairs in this order:\n",
    "# [(0,1), (1,2), (2,3), (3,4), (4,5)].\n",
    "# We invert that list once so each (i, j) → correct discrete index.\n",
    "PAIR_TO_INDEX = {(0, 1): 0, (1, 2): 1, (2, 3): 2, (3, 4): 3, (4, 5): 4}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "def main():\n",
    "    env = ExchangeCNOTEnvDI(\n",
    "        max_depth=len(gate_specs) + 2,   # small cushion\n",
    "        obs_mode=\"both\"                  # whatever you like → \"block\"|\"full\"|\"both\"\n",
    "    )\n",
    "    env.reset()\n",
    "\n",
    "    print(\"\\nReplay of fw_target gate list:\")\n",
    "    print(\"step |  pair  |      p       |  reward   | fidelity\")\n",
    "    print(\"-----+--------+--------------+-----------+----------\")\n",
    "\n",
    "    for step_idx, (p, (i, j)) in enumerate(gate_specs, 1):\n",
    "        pair_idx = PAIR_TO_INDEX[(i, j)]\n",
    "        _, reward, done, _ = env.step((pair_idx, p))\n",
    "\n",
    "        # compute fidelity wrt the published target circuit\n",
    "        fid_now = float(_fidelity(jnp.asarray(env.U), jnp.asarray(U_circuit)))\n",
    "\n",
    "        print(f\"{step_idx:4d} | {i}-{j}  | {p:+.6f} | {reward:+9.3f} | {fid_now:8.6f}\")\n",
    "\n",
    "        if done:\n",
    "            print(f\"\\nEpisode terminated early by reward logic at step {step_idx}.\\n\")\n",
    "            break\n",
    "\n",
    "    # final sanity check\n",
    "    if not done:\n",
    "        frob_dist = jnp.linalg.norm(env.U - U_circuit)\n",
    "        assert math.isclose(fid_now, 1.0, abs_tol=1e-6) and frob_dist < 1e-6, \\\n",
    "            \"Replay finished but circuit differs from target!\"\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497e4bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/schiffer98/QCRL/QCRL_v0.2/exch_gym_env.py:312: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pair_idx, p = int(action[0]), float(action[1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[debug] step 1  raw_reward=13.0\n",
      "step 01 pair=3 p=+1.695913  reward=+13.000000  fid64=0.067011  fid9=0.155245\n",
      "[debug] step 2  raw_reward=5.0\n",
      "step 02 pair=4 p=+0.108173  reward=+5.000000  fid64=0.064629  fid9=0.152741\n",
      "[debug] step 3  raw_reward=97.0\n",
      "Episode finished early at step 3\n"
     ]
    }
   ],
   "source": [
    "test_gate_sequence_runs_cleanly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87cb2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fidelity(A: np.ndarray, B: np.ndarray) -> float:\n",
    "\n",
    "    \"\"\"\n",
    "    Computes the fidelity between two square matrices A and B.\n",
    "    Fidelity is defined as:\n",
    "    F(A, B) = (Tr(A†A) + |Tr(B†A)|²) / (n * (n + 1))\n",
    "\n",
    "    updated from using just falttened inner product divided by product of norms.\n",
    "\n",
    "    # inner = jnp.vdot(A, B)\n",
    "    # return jnp.abs(inner) / (jnp.linalg.norm(A) * jnp.linalg.norm(B))\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if A.shape != B.shape or A.ndim != 2 or A.shape[0] != A.shape[1]:\n",
    "        raise ValueError(\"A and B must be square matrices of the same size\")\n",
    "\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # --- core computation ----------------------------------------------------\n",
    "    term1 = np.trace(A.conj().T @ A)                 # Tr(A†A)\n",
    "    term2 = np.trace(B.conj().T @ A)                 # Tr(B†A)\n",
    "    fidelity_val = (term1 + abs(term2)**2) / (n * (n + 1))\n",
    "\n",
    "    return fidelity_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efc729fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9954603734941675+8.045487353259573e-14j)\n"
     ]
    }
   ],
   "source": [
    "from fw_target import U_circuit as TARGET_FULL\n",
    "\n",
    "\n",
    "print(_fidelity(TARGET_FULL, TARGET_FULL))  # should be 1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
